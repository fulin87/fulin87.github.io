<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2B程序员的笔记</title>
    <description></description>
    <link>http://colorful.ren/</link>
    <atom:link href="http://colorful.ren/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 28 Oct 2016 13:18:22 +0800</pubDate>
    <lastBuildDate>Fri, 28 Oct 2016 13:18:22 +0800</lastBuildDate>
    <generator>Jekyll v3.0.0</generator>
    
      <item>
        <title>Linux中的文件大小和磁盘占有空间的关系</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#crontab-&quot; id=&quot;markdown-toc-crontab-&quot;&gt;crontab 定时任务产生的问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;解决办法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;启示&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;文件的真实大小和文件占有的磁盘空间不是一回事，根本的原因是由于系统和磁盘的存储机制决定的。最具有代表性的是crontab定时任务执行之后由sendmail产生的文件。下面详细分析一下整个过程。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;crontab-&quot;&gt;crontab 定时任务产生的问题&lt;/h2&gt;

&lt;p&gt;现在有一台服务器A&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 5.4 (Tikanga)

# rpm -qa|grep sendmail
sendmail-8.13.8-2.el5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是centos 5.4这个版本，而且已经安装了sendmail软件。&lt;/p&gt;

&lt;p&gt;有几个crontab定时任务&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 * * * * /data/jobscripts/run_status60.sh
0 * * * * /data/jobscripts/run_statusin.sh
*/5 7-23 * * * /data/jobscripts/run_sendsms.sh
*/5 * * * * /data/jobscripts/adjustment_product_store.sh
0 3 * * * /data/jobscripts/collate_product_store.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意这里这里的定时任务都没有对标准输出和标准错误输出进行重定向到/dev/null文件，那么这样做有什么隐患呢？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;定时任务启动之后，发现 &lt;code&gt;/var/spool/clientmqueue/&lt;/code&gt; 目录下的文件开始不断增加，这是一年之后我无意中发现的情况：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ls -lihd /var/spool/clientmqueue/
2080777 drwxrwx--- 2 smmsp smmsp 12M Oct 28 11:36 /var/spool/clientmqueue/

# du -h /var/spool/clientmqueue/
1.4G    /var/spool/clientmqueue/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现没有，目录 &lt;code&gt;/var/spool/clientmqueue/&lt;/code&gt; 实际的大小只有12M，但是占有的磁盘空间确达到了1.4G，是不是非常奇怪？继续排查。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ls -lih /var/spool/clientmqueue/ | wc -l
345047

# ls -lih /var/spool/clientmqueue/ | head -5
total 1.4G
2080837 -rw-rw---- 1 smmsp smmsp  880 Jan 23  2014 dfs0NEf1nJ007902
2080823 -rw-rw---- 1 smmsp smmsp  880 Jan 23  2014 dfs0NEK15v025165
2080839 -rw-rw---- 1 smmsp smmsp  880 Jan 23  2014 dfs0NEp1UL009526
2080836 -rw-rw---- 1 smmsp smmsp  880 Jan 23  2014 dfs0NEV2M6006278
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看到这里，才恍然大悟，原来 &lt;code&gt;/var/spool/clientmqueue/&lt;/code&gt; 这个目录中的文件有345047个之多，但是每个文件却只有880 byte 大。这就造成了磁盘Block的大量浪费，所以才会有目录磁盘占用量远大于目录本身大小的情况。&lt;/p&gt;

&lt;p&gt;那么这些小文件是怎么来的呢？其实是crontab定时任务在执行之后，就会通过sendmail给任务所有者发送一个邮件，就产生了一个880 byte的小文件。每次执行都产生一个，日积月累，数量非常庞大，给系统的安全还造成了一个隐患。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;解决办法&lt;/h2&gt;

&lt;p&gt;其实解决办法非常简单，将定时任务的标准输出和标准错误输出重定向到 &lt;code&gt;/dev/null&lt;/code&gt; 即可，将定时任务改造如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 * * * * /data/jobscripts/run_status60.sh &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
0 * * * * /data/jobscripts/run_statusin.sh &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
*/5 7-23 * * * /data/jobscripts/run_sendsms.sh &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
*/5 * * * * /data/jobscripts/adjustment_product_store.sh &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
0 3 * * * /data/jobscripts/collate_product_store.sh &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;section-1&quot;&gt;启示&lt;/h2&gt;

&lt;p&gt;通过这个案例，知道了crontab定时任务有一个小小的风险，但是可以通过重定向到 &lt;code&gt;/dev/null&lt;/code&gt; 来解决。&lt;/p&gt;

&lt;p&gt;同时，对这个问题的深入剖析，可以帮助我们更加深刻的理解 Inode;Block 和文件存储的机制。&lt;/p&gt;
</description>
        <pubDate>Thu, 27 Oct 2016 13:07:11 +0800</pubDate>
        <link>http://colorful.ren/linux/2016/10/27/fildanddisk.html</link>
        <guid isPermaLink="true">http://colorful.ren/linux/2016/10/27/fildanddisk.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>正则表达式知识点</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;基本正则表达式&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;扩展正则表达式&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;正则表达式就是一套处理字符串的规则和方法，基本上是以行为单位对字符串进行处理，通过特殊符号的辅助，我们可以快速的过滤替换字符串，&lt;code&gt;这里的正则表达式不是linux中所有命令都能用的，大部分是三剑客（sed,grep,awk）用的，和开发语言使用的正则表达式有区别&lt;/code&gt;。&lt;/p&gt;

  &lt;p&gt;这里作为自己常用的正则表达式的一个汇总，也作为复习使用&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section&quot;&gt;基本正则表达式&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;^dog&lt;/code&gt; 以dog开头&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; ls -l /home | grep ^d  #过滤出/home目录下的子目录
 grep -v ^# /home/config.conf #过滤掉config.conf中的注释内容
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;[^dog]&lt;/code&gt; 不包含dog&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;dog$&lt;/code&gt; 以dog结尾&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; ls -Fl /home | grep /$ #过滤出/home目录下的子目录
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;^$&lt;/code&gt; 表示空行&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;.&lt;/code&gt; 表示且只能表示一个任意字符&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; grep &quot;\.&quot; /home/config.conf #过滤出config.conf中包含.的行
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;*&lt;/code&gt; 重复0个或多个前面的一个字符&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;.*&lt;/code&gt; 匹配所有字符&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;[]&lt;/code&gt; 配置包含有其中的字符的内容&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; grep &quot;[abc]&quot; /home/config.conf #匹配出不包含a,b,c字符的行
 grep &quot;[0-9]&quot; /home/config.conf #匹配出包含有数字的行
 grep &quot;[a-Z]&quot; /home/config.conf #匹配出包含有因为字符的行
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;[^]&lt;/code&gt; 作用和 &lt;code&gt;[]&lt;/code&gt; 刚好相反&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; grep &quot;[^0-9]&quot; /home/config.conf #匹配出含有数字之外字符的行
 grep &quot;[^a-Z]&quot; /home/config.conf #匹配出含有字母之外字符的行
 grep &quot;^[^t]&quot;  /home/config.conf #匹配出不是t开头的行
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;{n,m}&lt;/code&gt; 重复前一个字符n到m次&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;扩展正则表达式&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;+&lt;/code&gt; 重复前面的字符一次或多次&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; egrep &quot;s+&quot; /home/config.conf #匹配包含有s的行
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt; 重复0个或一个前面的字符&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; egrep &quot;s?&quot; /home/config.conf #匹配没有s或没有连续s的行
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;|&lt;/code&gt; 用或的方式查找多个符合条件的字符串
     egrep “ss|ff” /home/config.conf #匹配含有ss或ff的行&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 20 Oct 2016 13:07:11 +0800</pubDate>
        <link>http://colorful.ren/linux/2016/10/20/regular.html</link>
        <guid isPermaLink="true">http://colorful.ren/linux/2016/10/20/regular.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>系统学习Junit4</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#junit&quot; id=&quot;markdown-toc-junit&quot;&gt;Junit的官方信息&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;学习笔记&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;准备测试类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;测试方法一&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;测试方法二&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;测试过程和结果解读&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#junit4&quot; id=&quot;markdown-toc-junit4&quot;&gt;Junit4的生命周期&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#junit-1&quot; id=&quot;markdown-toc-junit-1&quot;&gt;Junit注解解释&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#junit-2&quot; id=&quot;markdown-toc-junit-2&quot;&gt;Junit源码解析&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;网友的精彩博客&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;减少程序中的bug的一个有效的方法是编写程序逻辑的同时编写测试用例，尽早发现问题。同时Junit作为开源类库， &lt;strong&gt;&lt;a href=&quot;http://www.oschina.net/news/73667/2016-top-100-java-library&quot;&gt;受欢迎程度&lt;/a&gt;&lt;/strong&gt; 是非常高的，已经成为java单元测试事实上的标准，有必要做深入的学习。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;junit&quot;&gt;Junit的官方信息&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;http://junit.org/junit4/&quot;&gt;Junit官网&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/junit-team/junit4&quot;&gt;github地址&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;学习笔记&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备测试类&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;TestCast1&lt;/code&gt;,&lt;code&gt;TestCast2&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package com.fulin.test.testJunt;
import org.junit.After;
import org.junit.AfterClass;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;

public class TestCast1{
	
	public TestCast1(){
		System.out.println(&quot;Constrctor...&quot;);
	}
	
	@Before
	public void before(){
		System.out.println(&quot;before&quot;);
	}
	
	@BeforeClass
	public static void beforeClass(){
		System.out.println(&quot;beforeClass&quot;);
	}
	
	@After
	public void after(){
		System.out.println(&quot;after&quot;);
	}
	
	@AfterClass
	public static void afterClass(){
		System.out.println(&quot;afterClass&quot;);
	}
	
	@Test
	public void test1(){
		System.out.println(&quot;test1&quot;);
	}
	
	@Test
	public void test2(){
		System.out.println(&quot;test2&quot;);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code&gt;package com.fulin.test.testJunt;

import org.junit.Test;

public class TestCast2 {
	@Test
	public void test3(){
		System.out.println(&quot;test3&quot;);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编写好测试类之后，就可以使用Junit4来运行测试类了。运行测试类的方法有两种：&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;测试方法一&lt;/h3&gt;

&lt;p&gt;使用Junit原生的JUnitCore.runClasses(Class…class)方法,如下所示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package com.fulin.test.testJunt;

import org.junit.runner.JUnitCore;
import org.junit.runner.Result;
import org.junit.runner.notification.Failure;

public class JunnerTest {

	public static void main(String[] args) {
		Result result = JUnitCore.runClasses(TestCast1.class,TestCast2.class);
		for (Failure fail : result.getFailures()) {
			System.out.println(fail.toString());
		}
		
		if(result.wasSuccessful()){
			System.out.println(&quot;All tests finished successfully...&quot;);
		}
	}
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;beforeClass
Constrctor...
before
test1
after
Constrctor...
before
test2
after
afterClass
test3
All tests finished successfully...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section-3&quot;&gt;测试方法二&lt;/h3&gt;

&lt;p&gt;使用eclipse这个IDE自带的测试工具，在测试类中 &lt;code&gt;右键-&amp;gt; run as -&amp;gt; Junit Test&lt;/code&gt; 也可以得到相同的结果&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;测试过程和结果解读&lt;/h3&gt;

&lt;h4 id=&quot;junit4&quot;&gt;Junit4的生命周期&lt;/h4&gt;

&lt;p&gt;Junit4提供了一系列的注解，给编写测试测试类提供了极大的便利，也减少了侵入性。在不同的方法和字段上使用不同的注解，会有不同的效果。但是正真的测试核心方法还是 &lt;code&gt;@Test&lt;/code&gt; 标注的方法，其他都是围绕这个核心展开的，相当于其生命周期的一部分。&lt;/p&gt;

&lt;p&gt;同时，我们发现，不过是用那种测试方法，最终的结果都一样，我们有理由相信，Junit4的测试入口就是JunitCore.runClasses。这也是接下来分析源码的入口。&lt;/p&gt;

&lt;h4 id=&quot;junit-1&quot;&gt;Junit注解解释&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;1. @Test :   测试方法，测试程序会运行的方法
             后边可以跟参数代表不同的测试如
             (expected=XXException.class) 异常测试
             (timeout=xxx)超时测试
2. @Ignore : 被忽略的测试方法
3. @Before : 每一个测试方法之前运行
4. @After :  每一个测试方法之后运行
5. @BeforeClass: 所有测试开始之前运行
6. @AfterClass:  所有测试结束之后运行
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;junit-2&quot;&gt;Junit源码解析&lt;/h3&gt;

&lt;p&gt;这是根据Junit源码画出的时序图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/image/Junit-time.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;网友的精彩博客&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/pangyangyang/blog/144495&quot;&gt;Junit学习系列一&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/pangyangyang/blog/146015&quot;&gt;Junit学习系列二&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/pangyangyang/blog/153320&quot;&gt;Junit学习系列三&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 14 Oct 2016 13:07:11 +0800</pubDate>
        <link>http://colorful.ren/java/2016/10/14/junit.html</link>
        <guid isPermaLink="true">http://colorful.ren/java/2016/10/14/junit.html</guid>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>FastJson的使用与源码解读</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/alibaba/fastjson/wiki&quot;&gt;FastJSON&lt;/a&gt;&lt;/strong&gt;是一个处理&lt;strong&gt;&lt;a href=&quot;http://json.org&quot;&gt;JSON&lt;/a&gt;&lt;/strong&gt;的 java 工具包， json （反序列化）和对象转 json （序列化）两部分的功能。是由阿里使用Apache License 2.0协议开源，易用，无依赖，性能优越，唯一不足的是文档不完善，用户需要自己根据源码来摸索。这里记录一下自己的学习历程，作为我膜拜大师杰作，虚心偷技的成果，也方便来者学习。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section&quot;&gt;主要功能&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;FastJson的最主要的使用入口是 com.alibaba.fastjson.JSON 的一系列静态方法&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; // 把JSON文本parse为JSONObject或者JSONArray 
 public static final Object parse(String text); 
 // 把JSON文本parse成JSONObject
 public static final JSONObject parseObject(String text)； 
 // 把JSON文本parse为JavaBean
 public static final  T parseObject(String text, Class clazz); 
 // 把JSON文本parse成JSONArray
 public static final JSONArray parseArray(String text); 
 // 把JSON文本parse成JavaBean集合
 public static final  List parseArray(String text, Class clazz); 
 // 将JavaBean序列化为JSON文本
 public static final String toJSONString(Object object); 
 // 将JavaBean序列化为带格式的JSON文本 
 public static final String toJSONString(Object object, boolean prettyFormat); 
 // 将JavaBean转换为JSONObject或者JSONArray。
 public static final Object toJSON(Object javaObject); 
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;FastJson 的相关类的说明&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; SerializeWriter：	相当于StringBuffer
 JSONArray：			相当于List&amp;lt;Object&amp;gt;
 JSONObject：			相当于Map&amp;lt;String, Object&amp;gt;
 JSON反序列化没有真正的数组，本质类型都是List&amp;lt;Object&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;FastJson 的高级特性&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;支持注解、支持全类型序列化，这些都是很好的特性，功能强大&lt;/em&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;序列化形式可以自定义和灵活选择&lt;/p&gt;

        &lt;pre&gt;&lt;code&gt;  比如有一个注解：@JSONField;就可以实现序列号和反序列化的时候bean的属性名的灵活配置，非常实用。
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;源码解析&lt;/h3&gt;

 	&lt;img src=&quot;/image/fastJson.PNG&quot; alt=&quot;test&quot; /&gt;

&lt;p&gt;已经有前辈总结了心得,可以先理解透彻再自己去看源代码。
 记录在此，以后来完善。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.csdn.net/article/2014-09-25/2821866&quot;&gt;FastJson的源码研究&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.iteye.com/topic/1113183&quot;&gt;FastJson为什么这么快&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://blog.csdn.net/u010246789/article/details/52539576&quot;&gt;FastJson SerializerFeature的使用&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Oct 2016 13:07:11 +0800</pubDate>
        <link>http://colorful.ren/java/2016/10/10/fastjson.html</link>
        <guid isPermaLink="true">http://colorful.ren/java/2016/10/10/fastjson.html</guid>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>忒修斯之船 &amp; 数据库</title>
        <description>&lt;p&gt;&lt;code&gt;这是一个古老的哲学问题&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;忒修斯的船在海上航行了几百年,它被不间断地维修和替换部件。只要一块木板腐烂了，它就会被替换掉，以此类推，直到所有的功能部件都不是最开始的那些了。
问题是，最终产生的这艘船是否还是原来的那艘特修斯之船，还是一艘完全不同的船？如果不是原来的船，那么在什么时候它不再是原来的船了？
哲学家托马斯·霍布斯后来对此进来了延伸，如果用特修斯之船上取下来的老部件来重新建造一艘新的船，那么两艘船中哪艘才是真正的特修斯之船？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;几百年来，人们在这个问题上争论不休，谁也不能彻底说服对方，但是这个看似不能解决的问题却能带给我们一定的启发，那就是可以解释生活中的现象&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;一群能力超群的软件工程师在一家软件公司工作，做了一个伟大的产品，经过几年的迭代，产品从UI到逻辑，甚至数据库结构都发生了翻天覆地的变化，以至于这个产品最初的创造者也看不懂它的源代码了，越来越多的人开始吐槽……&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;问题来了，这个产品还是原来的那个伟大的产品吗？&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;渐变&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;数据库中有一条SKU的数据记录，本来SKU编码可以用来识别这条数据的唯一性。
可惜，一开始的时候为了图方便没有定好编码生成规则，后来需要改。
这一改麻烦了，唯一性只好由SKU的ID来负责，这也带来了一连串的问题因为
SKU的编码原本不仅有唯一性的约束功能，还有很多识别功能，而ID显然是没有。
因为变更，也带来的新的问题：怎样监控变更的历史。
于是诸如这样新的字段被不断加入

&quot;update_time ; insert_time ; update_user ; last_status&quot;

这些新增的信息让我们能尽可能多的追溯到当时的场景，可是这样好吗？
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;悲哀的是，现实中大部分的软件系统，都无法逃脱冗余和混乱的宿命，这也再次印证了物理中“熵”的概念：任何事物都是朝混乱度大的方向发展。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;质变&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;如果不是原来的船，那么在什么时候它不再是原来的船了?&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;当唯一识别标示失效的时候，它就不再是原来的船了。可是，什么是唯一识别标示？
身份证可以伪装，DNA都有可能相同，茫茫人海，是有可能存在两个你无法区分的人的。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;世界上不存在绝对的唯一性，所谓的唯一只存在于我们的想象中&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;启示&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;“任何系统熵都是逐渐变大的，自然状态下无法逆转，若想改变，必须做功。”
这一物理学的规律同样适用于现实生活。虽然我们无法做的绝对，但是可以尽量精确。
流程和标准就是行之有效的方法，甚至是唯一可行的方法。
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Mon, 10 Oct 2016 13:07:11 +0800</pubDate>
        <link>http://colorful.ren/life/2016/10/10/tui-xiu-shi-db.html</link>
        <guid isPermaLink="true">http://colorful.ren/life/2016/10/10/tui-xiu-shi-db.html</guid>
        
        
        <category>life</category>
        
      </item>
    
      <item>
        <title>杨德昌的那些经典电影</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;在今年的十一国庆，老婆带着孩子回老家了，我一个人在家，这是少有的属于自己的时间，从一个安静的上午一直持续到晚上，我默默的看完了杨德昌的《一 一》;《枯岭街少年杀人事件》;《恐怖分子》这三部电影，这是迄今为止，我看过的最好看的几部华语电影，没有之一，看完之后，我感觉我的世界观都变了……&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section&quot;&gt;慢的力量&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;看似缓慢舒缓的叙事背后，却隐藏着巨大的力量，这是看这几部电影最大的感受。
让我从此喜欢上了一切&quot;慢&quot;的事物，突然发现周围的一切都协调了。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section-1&quot;&gt;改变了又能怎么样&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;这是《一 一》里面的一句台词，“多年之后，和当年的初恋再次相遇，虽然都依然爱着对方，又能怎么样？
我现在至少还有家人。” 这场景本身慢慢体会，就已经很有意思了。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section-2&quot;&gt;真正的恐怖分子就在日常生活之中&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;《恐怖分子》中，男主人公长期受到生活的压抑，面对老婆的离去和朋友的小看，依然隐忍。
在工作中他心胸狭窄，为了升迁不惜出卖朋友，为了生活他很少和朋友联系。
在得知自己没有升迁，老婆背叛之后，梦到自己的复仇，可惜这一切都是幻想，最终只能自我了断。
看完这部电影，让人有一种说不出的苍凉感和无力感还有恐惧感，男主人为何会有这个结局。
我想导演已经通过台词说了：&quot;我很少看书，也不看小说&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;看杨导的电影，需要极大的耐心，他的电影都很长，有的一部就有4个小时。白水煮豆腐似得叙事风格，温暖的音乐元素，鲜明的时代感和深刻的哲思，让人身临其境，看完意犹未尽发人深省，我想这可能就是大师吧。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Sat, 08 Oct 2016 00:00:00 +0800</pubDate>
        <link>http://colorful.ren/life/2016/10/08/move-yangdecang.html</link>
        <guid isPermaLink="true">http://colorful.ren/life/2016/10/08/move-yangdecang.html</guid>
        
        
        <category>life</category>
        
      </item>
    
      <item>
        <title>mysql中sql优化的常识总结</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;mysql的性能优化牵扯的范围很广，大致可以分为：
索引优化，查询优化，查询缓存，服务器设置优化，操作系统和硬件优化，应用层面优化（web服务器，缓存）等等。这里仅仅总结一下编写sql语句时应该注意的细节。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;sql&quot;&gt;编写高质量的sql语句的基本原则&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;尽量避免全表扫描&lt;/li&gt;
  &lt;li&gt;查询尽量使用索引&lt;/li&gt;
  &lt;li&gt;尽量避免排序&lt;/li&gt;
  &lt;li&gt;DML语句尽量在一个数据库事务中完成&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;具体的优化技巧如下&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;1,禁止使用　select * from table ;尽量查询特定的字段.
  select * 会增加数据库开销

2,尽量不使用游标.
  游标比常规的sql语句需要更大的开销

3,尽量不要在索引字段上进行运算.
  在索引字段上进行运算会使索引失效

4,避免使用!=或＜＞、IS NULL或IS NOT NULL、IN ，NOT IN等这样的操作符.
  这会使系统无法使用索引,而只能直接搜索表中的数据，有些还是全表扫描

5,尽量使用数字型字段.
  如果字段是字符串类型，数据库引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了

6,合理使用EXISTS,NOT EXISTS子句
  如果需要判断记录是否存在，直接合理使用EXISTS,NOT EXISTS子句比count的效率要高，也比in的性能要高

7,能够用BETWEEN的就不要用IN

8,能够用DISTINCT的就不用GROUP BY

9,尽量不要用SELECT INTO语句。SELECT INTO 语句会导致表锁定，阻止其他用户访问该表

10,必要时强制查询优化器使用某个索引

11,能用UNION ALL就不要用UNION
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;这些可以说是sql语句优化的基本常识了，必须会使用，熟练使用。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Tue, 27 Sep 2016 00:00:00 +0800</pubDate>
        <link>http://colorful.ren/mysql/2016/09/27/mysql-right.html</link>
        <guid isPermaLink="true">http://colorful.ren/mysql/2016/09/27/mysql-right.html</guid>
        
        
        <category>mysql</category>
        
      </item>
    
      <item>
        <title>mysql的数据备份和恢复</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#mysql&quot; id=&quot;markdown-toc-mysql&quot;&gt;mysql的二进制日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;数据库的备份和恢复是每个DBA必须掌握的技能。作为开发人员来说，适当的了解，也是有必要的。曾经我就遇到过一个面试官问过我：是否会进行数据库备份和恢复，什么是热备份，什么是冷备份。当然，我不能说这是DBA的工作，只能怪自己学的不够广。当学会了数据库的备份和恢复，再次使用数据库的时候，视野就更开阔了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mysql&quot;&gt;mysql的二进制日志&lt;/h3&gt;

&lt;p&gt;说起mysql的备份和恢复，就必须说mysql的二进制日志，它记录的是所有mysql数据库发生变更的信息，因此对数据库非常重要&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;主要作用有以下几个方面&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;可以用于数据库基于时间点的还原&lt;/li&gt;
      &lt;li&gt;可以用来分析数据库发生变更的情况，比如程序程序bug导致数据库数据更改等。&lt;/li&gt;
      &lt;li&gt;二进制日志还可以用来重建数据库&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;二进制日志功能配置&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;开启bin_log日志功能,在my.cnf中修改，在[mysqld]下增加:&lt;/p&gt;

        &lt;pre&gt;&lt;code&gt; log-bin=/tmp/mysql-log
 binlog_format=mixed
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看二进制日志功能是否开启&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; show variables like &#39;%log_bin%&#39;;
 +---------------------------------+----------------------+
 | Variable_name                   | Value                |
 +---------------------------------+----------------------+
 | log_bin                         | ON                   |
 | log_bin_basename                | /tmp/mysql-log       |
 | log_bin_index                   | /tmp/mysql-log.index |
 | log_bin_trust_function_creators | OFF                  |
 | log_bin_use_v1_row_events       | OFF                  |
 | sql_log_bin                     | ON                   |
 +---------------------------------+----------------------+
 6 rows in set
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看二进制文件的情况&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; show master logs;
 +------------------+-----------+
 | Log_name         | File_size |
 +------------------+-----------+
 | mysql-log.000001 |       143 |
 | mysql-log.000002 |       562 |
 +------------------+-----------+
 2 rows in set
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;或者&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; show binary logs;
 +------------------+-----------+
 | Log_name         | File_size |
 +------------------+-----------+
 | mysql-log.000001 |       143 |
 | mysql-log.000002 |       562 |
 +------------------+-----------+
 2 rows in set
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;切换二进制文件&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; flush logs;
 Query OK, 0 rows affected

 mysql&amp;gt; show binary logs;
 +------------------+-----------+
 | Log_name         | File_size |
 +------------------+-----------+
 | mysql-log.000001 |       143 |
 | mysql-log.000002 |       609 |
 | mysql-log.000003 |       120 |
 +------------------+-----------+
 3 rows in set
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;删除或者初始化二进制文件&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; reset master;
 Query OK, 0 rows affected
	
 mysql&amp;gt; show binary logs;
 +------------------+-----------+
 | Log_name         | File_size |
 +------------------+-----------+
 | mysql-log.000001 |       120 |
 +------------------+-----------+
 1 row in set
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;指定二进制日志失效期&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; show variables like &quot;%expire%&quot;;
 +--------------------------------+-------+
 | Variable_name                  | Value |
 +--------------------------------+-------+
 | disconnect_on_expired_password | ON    |
 | expire_logs_days               | 0     |
 +--------------------------------+-------+
 2 rows in set

 mysql&amp;gt; set global  expire_logs_days=5;
 Query OK, 0 rows affected
	
 mysql&amp;gt; show variables like &quot;%expire%&quot;;
 +--------------------------------+-------+
 | Variable_name                  | Value |
 +--------------------------------+-------+
 | disconnect_on_expired_password | ON    |
 | expire_logs_days               | 5     |
 +--------------------------------+-------+
 2 rows in set
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;二进制日志的格式的查看和格式介绍,这里仅做了解,有三种&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; mysql&amp;gt; show variables like &#39;%format%&#39;;
 +--------------------------+-------------------+
 | Variable_name            | Value             |
 +--------------------------+-------------------+
 | binlog_format            | MIXED             |
 | date_format              | %Y-%m-%d          |
 | datetime_format          | %Y-%m-%d %H:%i:%s |
 | default_week_format      | 0                 |
 | innodb_file_format       | Antelope          |
 | innodb_file_format_check | ON                |
 | innodb_file_format_max   | Antelope          |
 | time_format              | %H:%i:%s          |
 +--------------------------+-------------------+
 8 rows in set

 Row : 日志中会记录成每一行数据被修改的形式，然后在 slave 端再对相同的数据进行修改
 Statement ： 每一条会修改数据的 SQL 都会记录到 master 的 bin-log 中。slave 在复制的时候 SQL 进程会解析成和原来 master 端执行过的相同的 SQL 再次执行。
 Mixed : MySQL 会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式，也就是在 statement 和 row 之间选择一种,相当于前两种的混合。
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看二进制日志文件的内容&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; # mysqlbinlog mysql-log.00000

 SET TIMESTAMP=1474882546/*!*/;
 insert into t select * from t
 /*!*/;
 # at 739
 #160926  2:35:46 server id 1  end_log_pos 770 CRC32 0x45bf6de6 	Xid = 98
 COMMIT/*!*/;
 # at 770
 #160926  2:35:47 server id 1  end_log_pos 849 CRC32 0xdcad682e 	Query	thread_id=1	exec_time=0	error_code=0
 SET TIMESTAMP=1474882547/*!*/;
 BEGIN
 /*!*/;
 # at 849
 #160926  2:35:47 server id 1  end_log_pos 952 CRC32 0x596b7cf9 	Query	thread_id=1	exec_time=0	error_code=0
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;仔细观察会发现，这里记录了数据库的每一次查询和修改过程，就像数据库的变更记录一样，难怪可以用来恢复数据。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 26 Sep 2016 00:00:00 +0800</pubDate>
        <link>http://colorful.ren/mysql/2016/09/26/mysql-log.html</link>
        <guid isPermaLink="true">http://colorful.ren/mysql/2016/09/26/mysql-log.html</guid>
        
        
        <category>mysql</category>
        
      </item>
    
      <item>
        <title>全栈还是专攻，这是一个问题</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;经常会浏览一下招聘网站，一方面，可以了解现在的市场行情，另一方面，可以了解目前行业使用的技术都有什么，具体有些什么要求，这是我根据我浏览很多信息之后的一点感悟&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;以下是我在某job上截取的一段用人单位的提出的技能要求:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、计算机相关专业本科及以上学历，3年以上Java开发工作经验；
2、熟悉MVC设计模式，熟悉Java领域常用的开源框架，如Spring、Struts、Ibatis、Hibernate等；
3、熟悉面向对象编程思想和设计模式；
4、熟悉多线程编程，熟悉socket编程、WebService接口技术；
5、熟悉MINA、Volley等网络通信应用框架，有MINA开发经验者优先。
6、熟悉Oracle、MySql等数据库，并有开发经验；
7、熟悉linux/UNIX等操作系统，了解Shell；
8、较强的表达和沟通能力，善于团队合作；
9、互联网金融开发经验者优先，有大容量、高性能、高可用、分布式、架构设计经验者优先；
10、熟悉hadoop/spark等大数据应用框架优先
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;这是大部分互联网公司开出的技能要求，有的甚至更多。那么问题来了, 业内的人都知道，任何一项技术，要想熟练掌握，是需要沉淀的，有一个广为人知的说法叫一万小时理论也就是说一项技术需要熟练掌握需要至少刻意练习10000小时，也就是3年&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;回到上面的技能要求上，上面的任何一项技能都可以单独拎出来，写成一本书，够研究好几年的，有些技术甚至够研究一辈子了，比如上面提到的：&lt;strong&gt;&lt;em&gt;大容量、高性能、高可用、分布式、hadoop/spark&lt;/em&gt;&lt;/strong&gt;，先不说其他的，单单能同时掌握这些，就已经属于稀有天才了。&lt;/p&gt;

&lt;p&gt;互联网的后端技术都是围绕两个主题展开的&lt;em&gt;大数据量&lt;/em&gt;和&lt;em&gt;高并发&lt;/em&gt;。精通其中一项基本可以在职场纵横天下了。&lt;/p&gt;

&lt;p&gt;既然如此，用人单位为什么要提出如此苛刻的要求呢？我认为原因主要有以下几个方面：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;一线城市人力成本急剧上升，尤其是以信息技术为代表的IT行业&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; 一线城市的房价暴涨，想留住人才，薪资往往是最具有吸引力的，所以出现了现在大家知道的一线开发人员动辄月薪数万，因此用人单位希望招到能力强的人，一个人顶几个用，也就是说希望自己的员工是个多面手。
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;技术更新换代快，系统质量和用户体验要求越来越高&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; 用户对产品不断提出更高的要求，更好的用户体验。
 对这些功能最好的保证就是高水平的开发人员。
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;用人单位需要的是全而专的人&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; 认真开用人单位的用人要求，大部分都是要求&quot;熟悉&quot;，并没有要求&quot;精通&quot;。
 因此有理由相信用人单位需要的是视野开阔，对多种技术均有涉猎，但又能精通一两种的人
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;经过以上的分析，也知道以后自己的道路该怎么走了，那就是，既要要有知识的广度，也要有专业的深度。我认为，深度比广度重要。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Mon, 26 Sep 2016 00:00:00 +0800</pubDate>
        <link>http://colorful.ren/fulin/2016/09/26/job.html</link>
        <guid isPermaLink="true">http://colorful.ren/fulin/2016/09/26/job.html</guid>
        
        
        <category>fulin</category>
        
      </item>
    
      <item>
        <title>mysql中使用explain来分析Sql语句的性能</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;语法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;例子&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;SQL优化的基本思路就是，先找到性能差的语句，然后找到性能差的原因，然后优化。当我们找到目标SQL之后，可以使用explain来分析SQL语句的执行过程，说白了就是看看这个语句的执行计划，找到性能瓶颈。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section&quot;&gt;语法&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;explain &amp;lt;语句&amp;gt;  //explain是专门分析select等查询语句的执行计划的
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section-1&quot;&gt;例子&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;执行以下sql语句，看一下它的执行计划(&lt;em&gt;这是一个比较复杂的查询了，比较典型&lt;/em&gt;)&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; EXPLAIN 
     SELECT
         o.order_id,
         o.order_sn,
         o.parent_order_sn,
         o.outer_id,
         e.pay_work_code,
         o.add_time,
         o.order_source,
         p.product_id,
         p.product_num,
         p.product_name,
         p.sell_num,
         p.sell_price,
         t.cacle_time,
         t.order_id
     FROM
         gshop_order o
     LEFT JOIN gshop_order_product p ON o.order_id = p.order_id
     LEFT JOIN gshop_order_ext e ON o.order_id = e.order_id
     LEFT JOIN (
         SELECT
             g1.order_id,
             g1.order_sn,
             g1.parent_order_sn,
             g1.outer_id,
             g2.from_status,
             g2.add_time AS cacle_time,
             g2.to_status,
             count(*) AS nums
         FROM
             gshop_order g1
         LEFT JOIN gshop_order_log g2 ON g1.order_id = g2.order_id
         WHERE
             g1.order_belong = 3
         AND g1.order_status = 13
         AND g1.sfv_download = 0
         AND (
             g1.order_source = 22
             OR g1.order_source = 26
         )
         AND g2.from_status = 5
         AND g2.to_status = 13
         AND g2.add_time &amp;gt; 1472610864
         GROUP BY
             g1.order_id
     ) t ON o.order_id = t.order_id
     WHERE
         t.order_id IS NOT NULL
     ORDER BY
         t.cacle_time DESC
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;执行结果如下：&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; +----+-------------+------------+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+----------------------+------+-----------------------------+
 | id | select_type | table      | type   | possible_keys                                                                                                                                                 | key         | key_len | ref                  | rows | Extra                       |
 +----+-------------+------------+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+----------------------+------+-----------------------------+
 |  1 | PRIMARY     | &amp;lt;derived2&amp;gt; | ALL    | NULL                                                                                                                                                          | NULL        | NULL    | NULL                 |    2 | Using where; Using filesort |
 |  1 | PRIMARY     | o          | eq_ref | PRIMARY                                                                                                                                                       | PRIMARY     | 4       | t.order_id           |    1 | NULL                        |
 |  1 | PRIMARY     | p          | ref    | idx_orderid                                                                                                                                                   | idx_orderid | 4       | t.order_id           |    1 | NULL                        |
 |  1 | PRIMARY     | e          | eq_ref | order_id                                                                                                                                                      | order_id    | 4       | t.order_id           |    1 | NULL                        |
 |  2 | DERIVED     | g1         | ref    | PRIMARY,idx_userid,idx_ordersn,idx_addtime_status,idx_areanumber,idx_couponid,idx_parentorderid,idx_parentordersn,idx_paytime_payid,idx_shippingsn,idx_status | idx_status  | 1       | const                |    2 | Using where                 |
 |  2 | DERIVED     | g2         | ref    | idx_orderid                                                                                                                                                   | idx_orderid | 4       | gshop_db.g1.order_id |    1 | Using where                 |
 +----+-------------+------------+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+----------------------+------+-----------------------------+
 6 rows in set
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;explain 结果详解&lt;/p&gt;

    &lt;p&gt;看到	explain 出来的结果，相信初学者应该已经懵逼了，面对这种情况，千万不能慌，要沉住气，要相信 &lt;em&gt;“我们的宇宙是存在规律的，并且规律是可以被认识的”&lt;/em&gt;，其实就是说，所有的技术，只要认真学，都是可以学会的，下面对explain结果的每一个字段的含义进行解释&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; id
     SQL执行顺序的标识，执行顺序是从大到小，例子中最先执行的是id为2的，也就是说是从下往上执行的。

 select_type
     就是select的类型,有这么几种：
     SIMPLE ： 简单SELECT(不使用UNION或子查询等）
     primary ： 最外层的select，在有子查询的语句中，最外层的select就是primary
     union : union语句的第二个或者说是后面那一个
     DEPENDENT UNION : UNION中的第二个或后面的SELECT语句，取决于外面的查询
     UNION RESULT : UNION的结果
     SUBQUERY : 子查询中的第一个SELECT
     DEPENDENT SUBQUERY : 子查询中的第一个SELECT，取决于外面的查询
     DERIVED : 派生表的SELECT(FROM子句的子查询)

 table
     显示这一行的数据是关于哪张表的.有时不是真实的表名字,看到的derivedx(x是个数字,我的理解是第几步执行的结果)

 type
     这列很重要,显示了连接使用了哪种类别,有无使用索引.从最好到最差的连接类型为const、eq_reg、ref、range、indexhe和ALL
     system : 这是const联接类型的一个特例。表仅有一行满足条件.
     const : 表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const表很快，因为它们只读取一次！const用于用常数值比较PRIMARY KEY或UNIQUE索引的所有部分时
     eq_ref : 对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。eq_ref可以用于使用= 操作符比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。
     ref : 对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY（换句话说，如果联接不能基于关键字选择单个行的话），则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或&amp;lt;=&amp;gt;操作符的带索引的列。
     ref_or_null : 该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。
     index_merge : 该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。
     unique_subquery : 该类型替换了下面形式的IN子查询的ref：
         value IN (SELECT primary_key FROM single_table WHERE some_expr)
         unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。
     index_subquery : 该联接类型类似于unique_subquery。可以替换IN子查询
     range : 只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。当使用=、&amp;lt;&amp;gt;、&amp;gt;、&amp;gt;=、&amp;lt;、&amp;lt;=、IS NULL、&amp;lt;=&amp;gt;、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range
     index : 该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。当查询只使用作为单索引一部分的列时，MySQL可以使用该联接类型。
     ALL ： 对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。

 possible_keys
     possible_keys列指出MySQL能使用哪个索引在该表中找到行。注意，该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询

 key
     key列显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。

 key_len
     key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。使用的索引的长度。在不损失精确性的情况下，长度越短越好

 ref
     ref列显示使用哪个列或常数与key一起从表中选择行。

 rows
     rows列显示MySQL认为它执行查询时必须检查的行数。

 Extra
     该列包含MySQL解决查询的详细信息，下面是详细信息
     Distinct ： 一旦MYSQL找到了与行相联合匹配的行，就不再搜索了
     Not exists ： MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行就不再搜索了
     Range checked for each Record（index map:#）： 没有找到理想的索引，因此对于从前面表中来的每一个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一
     Using filesort www.2cto.com ： 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行
     Using index ： 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候
     Using temporary ： 看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上
     Using where ： 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有问题
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;本例的执行计划解读&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

  	sql语句的执行是按照执行计划从下往上执行的，从执行计划可以看出，最先执行的是表连接中的查询，生成临时表与其他表连接查询，其他表都走的是索引，唯独临时表使用的是全表扫描。
</description>
        <pubDate>Fri, 23 Sep 2016 00:00:00 +0800</pubDate>
        <link>http://colorful.ren/mysql/2016/09/23/mysql-explain.html</link>
        <guid isPermaLink="true">http://colorful.ren/mysql/2016/09/23/mysql-explain.html</guid>
        
        
        <category>mysql</category>
        
      </item>
    
  </channel>
</rss>
